<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on A Data Blog</title>
    <link>/post/</link>
    <description>Recent content in Posts on A Data Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>How Far in Advance Users Schedule Posts</title>
      <link>/2018/12/03/how-far-in-advance-users-schedule-posts/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/03/how-far-in-advance-users-schedule-posts/</guid>
      <description>Buffer is a tool that allows people to schedule their social media posts in advance. In this analysis we will explore how far in advance users schedule their posts. If users don’t schedule many posts very far out in advance, it may have some implications for how we develop the product in the future.
To do this we will compute some summary statistics for a sample of users that have scheduled posts in the past six months.</description>
    </item>
    
    <item>
      <title>Upgrades and Retention in New Publish</title>
      <link>/2018/12/03/upgrades-and-retention-in-new-publish/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/03/upgrades-and-retention-in-new-publish/</guid>
      <description>Over the past few months Buffer has been rolling out a newly designed dashboard, which we refer to as “New Publish”. The old dashboard, labeled “Buffer Classic”, is still being served to the majority of people who create a Buffer account.
The purpose of this analysis is to explore the rates at which people upgrade to paid plans in New Publish and Buffer Classic, and how long they took to do it.</description>
    </item>
    
    <item>
      <title>Analyzing Census Data in R</title>
      <link>/2018/11/29/analyzing-census-data-in-r/</link>
      <pubDate>Thu, 29 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/29/analyzing-census-data-in-r/</guid>
      <description>Let’s play with American Cummunity Survey (ACS) data. ACS data differ from decennial Census data in that ACS data are based on an annual sample of approximately 3 million households, rather than a more complete enumeration of the US population. In turn, ACS data points are estimates characterized by a margin of error.
Let’s see what data is available for Kentucky, the state I live in. We’ll analyze data at the county level.</description>
    </item>
    
    <item>
      <title>Deploying Deep Learning Models with CloudML</title>
      <link>/2018/11/28/deploying-deep-learning-models-with-cloudml/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/28/deploying-deep-learning-models-with-cloudml/</guid>
      <description>In this post we will go over deploying deep learning models to Google’s cloud machine learning engine in R with the keras and cloudml packages.
The cloudml package built by the good people of RSudio allows us to train deep learning models built with keras and tensorflow in the cloud. It also allows the deployment of trained models to the Google global prediction platform, which we can use to make predictions with a simple API call.</description>
    </item>
    
  </channel>
</rss>